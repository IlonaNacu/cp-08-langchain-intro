{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First example of LangChain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Focus: Why ðŸ¦œðŸ”— LangChain</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "âœ… Libraries loaded successfully <br>\n",
       "âœ… OpenAI Key loaded (...gK0Vfbay3JQopT3BlbkFJ1S9XN...)\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from util import local_settings\n",
    "\n",
    "display(HTML(f\"\"\"\n",
    "âœ… Libraries loaded successfully <br>\n",
    "âœ… OpenAI Key loaded (...{local_settings.OPENAI_API_KEY[10:-15]}...)\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¦œðŸ”—Â **Why do we need LangChain?**\n",
    "\n",
    "- Most of LLms (GPT-3.5, AI21Labs, LLaMA,â€¦) are not up to date\n",
    "- They are **not** good atÂ **Domain Knowledge** and **fail** when working with **Proprietary Data**\n",
    "- Working with different LLMs may become a tedious task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- LLM's don't always produce the same results. The results you see in this notebook may differ from the results you see in the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For example, ask a simple question about a fictional character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- response -----\n",
      "\n",
      "\n",
      "Sorry, I do not have information about Ferdinando .\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name =\"text-davinci-003\")\n",
    "\n",
    "person = \"Ferdinando Langchain\"\n",
    "\n",
    "prompt = f\"Who is {person}? How many prizes he won? Only respond if you effectively find information about this person. Otherwise, respond that you are sorry and do not have information about this person.\"\n",
    "\n",
    "response = llm(prompt, temperature = 0)\n",
    "\n",
    "print(\"----- response -----\")\n",
    "print(response.replace(\"Langchain\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\"><h3> ðŸ‘‰ Given that Ferdinando Langchain is a fictional character with a distinctive name, no records or information about him could be found.</h3></font>\n",
    "\n",
    "\n",
    "As an illustration, consider the task of loading a PDF file containing details about Ferdinando LangChain and then storing this information in a Vector Database. This process allows for efficient organization and retrieval of pertinent information for subsequent analysis within the context of artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the text of a PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16005\n"
     ]
    }
   ],
   "source": [
    "pdf_data = PdfReader(\"./context/biographies.pdf\")\n",
    "\n",
    "pdf_text = \"\"\n",
    "\n",
    "for i, page in enumerate(pdf_data.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        pdf_text += text\n",
    "\n",
    "print(len(pdf_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the text into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    # of Chunks: 59\n",
      "    Chunk 0: Ferdinando Langchain: Pioneering AI Engineer and Visionary  \n",
      " \n",
      "Ferdinando Langchain was born on a brisk winter day in 1985 in Milan, Italy. From an early \n",
      "age, he displayed an insatiable curiosity about technology and a keen interest in \n",
      "understanding the mysteries of artificial intelligence. His journey into AI began when he\n",
      "    Chunk 1: understanding the mysteries of artificial intelligence. His journey into AI began when he \n",
      "stumbled upon an old computer in his father's study, sparking a fascination that would \n",
      "shape his future.  \n",
      " \n",
      "After completing his undergraduate studies in computer science at the University of Milan, \n",
      "Ferdinando ventured to the United States to pursue a Ph.D. in Artificial Intelligence at the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 400,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "\n",
    "final_data = text_splitter.split_text(pdf_text)\n",
    "\n",
    "print(f\"\"\"\n",
    "    # of Chunks: {len(final_data)}\n",
    "    Chunk 0: {final_data[0]}\n",
    "    Chunk 1: {final_data[1]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings and store the texts and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who is Ferdinando Langchain? How many prizes he won? Only respond if you effectively find information about this person. Otherwise, respond that you are sorry and do not have information about this person.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "document_searcher = FAISS.from_texts(final_data, embeddings)\n",
    "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/llm_vector-db_bio.png\" width=\"700px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§  Now, you just need to ask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ask and obtain the proper response, you must search the documents related to the question in the vector store. Subsequently, pass both the retrieved documents and the prompt to the model through a chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ðŸ¤– RESULT ---\n",
      "\n",
      "Ferdinando Langchain is a pioneering AI engineer and visionary who was born in 1985 in Milan, Italy. He won three prestigious international prizes for his contributions to the field of artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "person = \"Ferdinando Langchain\"\n",
    "\n",
    "prompt = f\"Who is {person}? How many prizes he won? Only respond if you effectively find information about this person. Otherwise, respond that you are sorry and do not have information about this person.\"\n",
    "\n",
    "docs =  document_searcher.similarity_search(prompt)\n",
    "result = chain.run(input_documents=docs, question=prompt)\n",
    "\n",
    "print(\"--- ðŸ¤– RESULT ---\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">\n",
    "<h1>ðŸ‘‡ look here</h1>\n",
    "Note that, in the result of the following cell, only documents (texts) that have an effective relationship with the question were returned. In this case, only will be passed the documents related to the question. As a result, we reduce considerably the number of tokens passed to the model. This is important, as it optimizes your costs by using API calls more efficiently.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Ferdinando Langchain: Pioneering AI Engineer and Visionary  \\n \\nFerdinando Langchain was born on a brisk winter day in 1985 in Milan, Italy. From an early \\nage, he displayed an insatiable curiosity about technology and a keen interest in \\nunderstanding the mysteries of artificial intelligence. His journey into AI began when he'), Document(page_content='As Ferdinando Langchain continued his journey in the evolving landscape of artificial \\nintelligence, his impact on the field and society at large became increasingly profound. His \\nvision of creating a beneficial and inclusive AGI echoed through the corridor s of innovation, \\nleaving an indelible mark on the future of artificial intelligence.  \\n \\nMortimer Quicksilver - Steampunk Inventor'), Document(page_content=\"models that could generalize across a wide range of tasks earned him widespread accl aim. \\nNotably, his research contributed to advancements in natural language processing, \\ncomputer vision, and robotics.  \\n \\nFerdinando's dedication and brilliance did not go unnoticed. In a span of just a few years, he \\nwas awarded three prestigious international prizes for his outstanding contributions to the\"), Document(page_content='He mentored aspiring AI researchers, fostering a sense of community within the field. His \\ncollaborative spirit extended beyond academia, as he engaged with policymaker s, ethicists, \\nand industry leaders to shape the ethical framework surrounding AI.  \\n \\nAs Ferdinando Langchain continued his journey in the evolving landscape of artificial')]\n"
     ]
    }
   ],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ðŸ¤– RESULT ---\n",
      "\n",
      "Zephyra Blazeheart is a scientist who was known for her work in astrophysics and research into the depths of the universe. She won the prestigious Astral Pioneer Award in recognition of her intellectual prowess and contributions to humankind's exploration of space.\n"
     ]
    }
   ],
   "source": [
    "person = \"Zephyra Blazeheart\"\n",
    "prompt = f\"Who is {person}? How many prizes he won? Only respond if you effectively find information about this person. Otherwise, respond that you are sorry and do not have information about this person.\"\n",
    "\n",
    "docs =  document_searcher.similarity_search(prompt)\n",
    "result = chain.run(input_documents=docs, question=prompt)\n",
    "\n",
    "print(\"--- ðŸ¤– RESULT ---\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='prestigious Astral Pioneer Award. This recognition not only celebrated her intellectual \\nprowess but also acknowledged her role in propelling humanity into a new era of \\nastrophysica l discovery. Zephyra Blazeheart became a beacon of inspiration for aspiring \\nscientists and stargazers alike, proving that even the most elusive cosmic mysteries could be'), Document(page_content=\"propelling her into the forefront of astrophysical exploration.  \\nZephyra Blazeheart's journey into the vast cosmos began under the radiant skies of \\nLuminara, a town with an otherworldly charm that seemed to inspire a sense of wonder in \\nthose who called it home. From a young age, Zephyra was insatiable and curious  about the \\nnight sky's celestial wonders .\"), Document(page_content=\"across the cosmos.  \\n As she continued her cosmic odyssey, Zephyra Blazeheart's name became synonymous with \\nthe spirit of exploration and the relentless pursuit of knowledge. Her research not only \\nexpanded the frontiers of quantum astrophysics but also served as a guiding light  for those \\nwho dared to gaze into the depths of the universe, reminding them that the cosmos, with all\"), Document(page_content=\"universe. Her theoretical contributions paved the way for practical applications in space \\nexplora tion and communication, earning her widespread acclaim in the scientific \\ncommunity.  \\n \\nThe crowning moment of Zephyra's career came when she was bestowed with the \\nprestigious Astral Pioneer Award. This recognition not only celebrated her intellectual\")]\n"
     ]
    }
   ],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"Yellow\">ðŸ‘‹ the end </font></h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

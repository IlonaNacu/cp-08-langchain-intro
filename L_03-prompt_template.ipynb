{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "073bf8f9",
   "metadata": {},
   "source": [
    "Lesson 3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßë‚Äçüç≥ LangChain: Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "* Direct API calls to OpenAI\n",
    "  \n",
    "* API calls through LangChain:\n",
    "  * Models  \n",
    "  * Prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ <font color=\"red\">Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the class.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ff606",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Settings\nHUGGINGFACEHUB_API_TOKEN\n  Field required [type=missing, input_value={'OPENAI_API_KEY': 'sk-gR...FJ1S9XN12F0ghIvpNQfMvH'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/fernandoperes/code/fajp-courses/cp-08-langchain-intro/L_03-prompt_template.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fernandoperes/code/fajp-courses/cp-08-langchain-intro/L_03-prompt_template.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fernandoperes/code/fajp-courses/cp-08-langchain-intro/L_03-prompt_template.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m local_settings\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fernandoperes/code/fajp-courses/cp-08-langchain-intro/L_03-prompt_template.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAI\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fernandoperes/code/fajp-courses/cp-08-langchain-intro/L_03-prompt_template.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39menv_colors\u001b[39;00m \u001b[39mimport\u001b[39;00m TerminalTextColor\n",
      "File \u001b[0;32m~/code/fajp-courses/cp-08-langchain-intro/util.py:50\u001b[0m\n\u001b[1;32m     46\u001b[0m     _ \u001b[39m=\u001b[39m load_dotenv(\u001b[39m\"\u001b[39m\u001b[39m.env\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[39m# print(os.getenv(\"OPENAI_API_KEY\")[0:-15])\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m local_settings \u001b[39m=\u001b[39m Settings()\n",
      "File \u001b[0;32m~/code/fajp-courses/cp-08-langchain-intro/env/lib/python3.10/site-packages/pydantic_settings/main.py:71\u001b[0m, in \u001b[0;36mBaseSettings.__init__\u001b[0;34m(__pydantic_self__, _case_sensitive, _env_prefix, _env_file, _env_file_encoding, _env_nested_delimiter, _secrets_dir, **values)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     61\u001b[0m     __pydantic_self__,\n\u001b[1;32m     62\u001b[0m     _case_sensitive: \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[39m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     72\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m__pydantic_self__\u001b[39m.\u001b[39;49m_settings_build_values(\n\u001b[1;32m     73\u001b[0m             values,\n\u001b[1;32m     74\u001b[0m             _case_sensitive\u001b[39m=\u001b[39;49m_case_sensitive,\n\u001b[1;32m     75\u001b[0m             _env_prefix\u001b[39m=\u001b[39;49m_env_prefix,\n\u001b[1;32m     76\u001b[0m             _env_file\u001b[39m=\u001b[39;49m_env_file,\n\u001b[1;32m     77\u001b[0m             _env_file_encoding\u001b[39m=\u001b[39;49m_env_file_encoding,\n\u001b[1;32m     78\u001b[0m             _env_nested_delimiter\u001b[39m=\u001b[39;49m_env_nested_delimiter,\n\u001b[1;32m     79\u001b[0m             _secrets_dir\u001b[39m=\u001b[39;49m_secrets_dir,\n\u001b[1;32m     80\u001b[0m         )\n\u001b[1;32m     81\u001b[0m     )\n",
      "File \u001b[0;32m~/code/fajp-courses/cp-08-langchain-intro/env/lib/python3.10/site-packages/pydantic/main.py:164\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    163\u001b[0m __tracebackhide__ \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m __pydantic_self__\u001b[39m.\u001b[39;49m__pydantic_validator__\u001b[39m.\u001b[39;49mvalidate_python(data, self_instance\u001b[39m=\u001b[39;49m__pydantic_self__)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Settings\nHUGGINGFACEHUB_API_TOKEN\n  Field required [type=missing, input_value={'OPENAI_API_KEY': 'sk-gR...FJ1S9XN12F0ghIvpNQfMvH'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from util import local_settings\n",
    "from openai import OpenAI\n",
    "\n",
    "from env_colors import TerminalTextColor\n",
    "\n",
    "model=\"gpt-3.5-turbo\"\n",
    "\n",
    "print(\"First LLM API example\")\n",
    "print(f\"‚úÖ OpenAI Key loaded (...{local_settings.OPENAI_API_KEY[20:-20]}...)\")\n",
    "print(f\"‚úÖ Model: {model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a92fb-8227-4513-8950-c965b822c425",
   "metadata": {},
   "source": [
    "> üîî <font color=\"#00d4d4\">**Note:** some characters of the key are omitted for security reasons.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=local_settings.OPENAI_API_KEY)\n",
    "\n",
    "def get_completion(prompt, temperature= 0, messages = [], model=model):\n",
    "\n",
    "    message = {\"role\": \"user\", \"content\": prompt}\n",
    "\n",
    "    messages.append(message)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"system\" : \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad9cdb",
   "metadata": {},
   "source": [
    "## Chat API : OpenAI\n",
    "\n",
    "Let's start with a direct API calls to OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    Email --> Format\n",
    "    Style_1 --> Format\n",
    "    Prompt_template --> Format\n",
    "    Format --> Prompt\n",
    "    Prompt --> LLM\n",
    "    LLM --> Response\n",
    "```\n",
    "The chain view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer e-mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b32b57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of\n",
    "cleaning up me kitchen. I need yer help right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c34459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "style = \"\"\"American English in a calm and respectful tone\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b558e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Translate the text that is delimited by triple backtick into a style that is {style}. In the end, add a portuguese translation of the response.\n",
    "\n",
    "text: ```{customer_email}```\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re.findall(r'{(.*?)}', prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.format( style=style, customer_email=customer_email )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_inputs = { \"style\":style, \"customer_email\":customer_email }\n",
    "prompt.format( **prompt_inputs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Translate the text that is delimited by triple backtick into a style that is {style}.\n",
    "In the end, add a portuguese translation of the response.\n",
    "text: ```{customer_email}```\"\"\"\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- PROMPT ------{TerminalTextColor.RESET}\")\n",
    "print(f\"{TerminalTextColor.GREEN}{prompt}{TerminalTextColor.RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883dcbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt)\n",
    "print(f\"{TerminalTextColor.BLUE}----- RESPONSE ------{TerminalTextColor.RESET}\")\n",
    "print(f\"{TerminalTextColor.YELLOW}{response}{TerminalTextColor.RESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80482d1",
   "metadata": {},
   "source": [
    "## Chat API : LangChain\n",
    "\n",
    "Let's try how we can do the same using LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    Email --> ChatPromptTemplate_1\n",
    "    Style_1 --> ChatPromptTemplate_1\n",
    "    Prompt_template_1 --> ChatPromptTemplate_1\n",
    "    ChatPromptTemplate_1 --> Prompt_1\n",
    "    Prompt_1 --> LLM_1\"Chat\"\n",
    "    LLM_1\"Chat\" --> Result_1\n",
    "    Service_response --> ChatPromptTemplate_2\n",
    "    Result_1 --> ChatPromptTemplate_2\n",
    "    Style_2 --> ChatPromptTemplate_2\n",
    "    Prompt_template_2 --> ChatPromptTemplate_2\n",
    "    ChatPromptTemplate_2 --> Prompt_2\n",
    "    Prompt_2 --> LLM_2\n",
    "    LLM_2 --> Final_Response\n",
    "```\n",
    "\n",
    "The chain view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mermaid.js.org/syntax/flowchart.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c5b27",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4a269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "model=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc0c8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0, model=model)\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- chat ------{TerminalTextColor.RESET}\")\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d07256",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31f246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bda7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text that is delimited by triple backticks \\\n",
    "into a style that is {style}. In the end, add a portuguese translation of the response.\n",
    "\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- prompt_template ------{TerminalTextColor.RESET}\")\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac2cb16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{TerminalTextColor.BLUE}----- ...messages[0].prompt ------{TerminalTextColor.RESET}\")\n",
    "\n",
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5566c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{TerminalTextColor.BLUE}----- input_variables ------{TerminalTextColor.RESET}\")\n",
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style and E-mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd51a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_completion(prompt=f\"translate the following text to portuguese. TEXT: ```{customer_email}```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3954f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "    style=customer_style, text=customer_email\n",
    ")\n",
    "print(f\"{TerminalTextColor.BLUE}----- type of customer_messages ------{TerminalTextColor.RESET}\")\n",
    "print(type(customer_messages))\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- type of customer_messages[0] ------{TerminalTextColor.RESET}\")\n",
    "print(type(customer_messages[0]))\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- customer_messages[0] ------{TerminalTextColor.RESET}\")\n",
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd789f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)\n",
    "print(f\"{TerminalTextColor.BLUE}----- RESPONSE ------{TerminalTextColor.RESET}\")\n",
    "\n",
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c267e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender.\n",
    "\n",
    "Tough luck! See ya!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff72bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_style_pirate = \"\"\"a polite tone that speaks in English Pirate\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e8f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print(service_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae5552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_response = chat(service_messages)\n",
    "print(service_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"Yellow\">üëã the end </font></h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

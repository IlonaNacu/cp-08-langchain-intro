{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "073bf8f9",
   "metadata": {},
   "source": [
    "Lesson 3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßë‚Äçüç≥ LangChain: Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "* Direct API calls to OpenAI\n",
    "  \n",
    "* API calls through LangChain:\n",
    "  * Models  \n",
    "  * Prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ <font color=\"red\">Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the class.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ff606",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First LLM API example\n",
      "‚úÖ OpenAI Key loaded (...UQiT3BlbkFJ...)\n",
      "‚úÖ Model: gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from util import local_settings\n",
    "from openai import OpenAI\n",
    "\n",
    "from env_colors import TerminalTextColor\n",
    "\n",
    "model=\"gpt-3.5-turbo\"\n",
    "\n",
    "print(\"First LLM API example\")\n",
    "print(f\"‚úÖ OpenAI Key loaded (...{local_settings.OPENAI_API_KEY[20:-20]}...)\")\n",
    "print(f\"‚úÖ Model: {model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a92fb-8227-4513-8950-c965b822c425",
   "metadata": {},
   "source": [
    "> üîî <font color=\"#00d4d4\">**Note:** some characters of the key are omitted for security reasons.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=local_settings.OPENAI_API_KEY)\n",
    "\n",
    "def get_completion(prompt, temperature= 0, messages = [], model=model):\n",
    "\n",
    "    message = {\"role\": \"user\", \"content\": prompt}\n",
    "\n",
    "    messages.append(message)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"system\" : \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad9cdb",
   "metadata": {},
   "source": [
    "## Chat API : OpenAI\n",
    "\n",
    "Let's start with a direct API calls to OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    Email --> Format\n",
    "    Style_1 --> Format\n",
    "    Prompt_template --> Format\n",
    "    Format --> Prompt\n",
    "    Prompt --> LLM\n",
    "    LLM --> Response\n",
    "```\n",
    "The chain view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer e-mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b32b57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of\n",
    "cleaning up me kitchen. I need yer help right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c34459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "style = \"\"\"American English in a calm and respectful tone\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80b558e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backtick into a style that is {style}. In the end, add a portuguese translation of the response.\n",
      "\n",
      "text: ```{customer_email}```\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Translate the text that is delimited by triple backtick into a style that is {style}. In the end, add a portuguese translation of the response.\n",
    "\n",
    "text: ```{customer_email}```\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['style', 'customer_email']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r'{(.*?)}', prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Translate the text that is delimited by triple backtick into a style that is American English in a calm and respectful tone. In the end, add a portuguese translation of the response.\\n\\ntext: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of\\ncleaning up me kitchen. I need yer help right now, matey!\\n```\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format( style=style, customer_email=customer_email )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Translate the text that is delimited by triple backtick into a style that is American English in a calm and respectful tone. In the end, add a portuguese translation of the response.\\n\\ntext: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of\\ncleaning up me kitchen. I need yer help right now, matey!\\n```\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_inputs = { \"style\":style, \"customer_email\":customer_email }\n",
    "prompt.format( **prompt_inputs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m----- PROMPT ------\u001b[0m\n",
      "\u001b[92mTranslate the text that is delimited by triple backtick into a style that is American English in a calm and respectful tone.\n",
      "In the end, add a portuguese translation of the response.\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of\n",
      "cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the text that is delimited by triple backtick into a style that is {style}.\n",
    "In the end, add a portuguese translation of the response.\n",
    "text: ```{customer_email}```\"\"\"\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- PROMPT ------{TerminalTextColor.RESET}\")\n",
    "print(f\"{TerminalTextColor.GREEN}{prompt}{TerminalTextColor.RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c883dcbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m----- RESPONSE ------\u001b[0m\n",
      "\u001b[93mI'm really frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I would greatly appreciate your help right now, my friend!\n",
      "\n",
      "Portuguese translation:\n",
      "Estou realmente frustrado que a tampa do meu liquidificador voou e respingou as paredes da minha cozinha com smoothie! E para piorar as coisas, a garantia n√£o cobre o custo de limpar minha cozinha. Eu ficaria muito grato pela sua ajuda agora, meu amigo!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "print(f\"{TerminalTextColor.BLUE}----- RESPONSE ------{TerminalTextColor.RESET}\")\n",
    "print(f\"{TerminalTextColor.YELLOW}{response}{TerminalTextColor.RESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80482d1",
   "metadata": {},
   "source": [
    "## Chat API : LangChain\n",
    "\n",
    "Let's try how we can do the same using LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    Email --> ChatPromptTemplate_1\n",
    "    Style_1 --> ChatPromptTemplate_1\n",
    "    Prompt_template_1 --> ChatPromptTemplate_1\n",
    "    ChatPromptTemplate_1 --> Prompt_1\n",
    "    Prompt_1 --> LLM_1\"Chat\"\n",
    "    LLM_1\"Chat\" --> Result_1\n",
    "    Service_response --> ChatPromptTemplate_2\n",
    "    Result_1 --> ChatPromptTemplate_2\n",
    "    Style_2 --> ChatPromptTemplate_2\n",
    "    Prompt_template_2 --> ChatPromptTemplate_2\n",
    "    ChatPromptTemplate_2 --> Prompt_2\n",
    "    Prompt_2 --> LLM_2\n",
    "    LLM_2 --> Final_Response\n",
    "```\n",
    "\n",
    "The chain view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mermaid.js.org/syntax/flowchart.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c5b27",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0d4a269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "model=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cc0c8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m----- chat ------\u001b[0m\n",
      "client=<openai.resources.chat.completions.Completions object at 0x103c32380> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11843a320> temperature=0.0 openai_api_key='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' openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0, model=model)\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- chat ------{TerminalTextColor.RESET}\")\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d07256",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a31f246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57bda7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m----- prompt_template ------\u001b[0m\n",
      "input_variables=['style', 'text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. In the end, add a portuguese translation of the response.\\n\\ntext: ```{text}```\\n'))]\n"
     ]
    }
   ],
   "source": [
    "template_string = \"\"\"Translate the text that is delimited by triple backticks \\\n",
    "into a style that is {style}. In the end, add a portuguese translation of the response.\n",
    "\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- prompt_template ------{TerminalTextColor.RESET}\")\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cac2cb16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m----- ...messages[0].prompt ------\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. In the end, add a portuguese translation of the response.\\n\\ntext: ```{text}```\\n')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{TerminalTextColor.BLUE}----- ...messages[0].prompt ------{TerminalTextColor.RESET}\")\n",
    "\n",
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdc5566c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m----- input_variables ------\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{TerminalTextColor.BLUE}----- input_variables ------{TerminalTextColor.RESET}\")\n",
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style and E-mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbd51a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No final, adicione uma tradu√ß√£o em portugu√™s da resposta.\\n\\nTexto: \\n```\\nEstou furioso porque a tampa do meu liquidificador voou e respingou as paredes da minha cozinha com smoothie! E para piorar as coisas, a garantia n√£o cobre o custo de limpar a minha cozinha. Preciso da sua ajuda agora mesmo, camarada!\\n```'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(prompt=f\"translate the following text to portuguese. TEXT: ```{customer_email}```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dff3954f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m----- type of customer_messages ------\u001b[0m\n",
      "<class 'list'>\n",
      "\u001b[94m----- type of customer_messages[0] ------\u001b[0m\n",
      "<class 'langchain.schema.messages.HumanMessage'>\n",
      "\u001b[94m----- customer_messages[0] ------\u001b[0m\n",
      "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. In the end, add a portuguese translation of the response.\\n\\ntext: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\"\n"
     ]
    }
   ],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "    style=customer_style, text=customer_email\n",
    ")\n",
    "print(f\"{TerminalTextColor.BLUE}----- type of customer_messages ------{TerminalTextColor.RESET}\")\n",
    "print(type(customer_messages))\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- type of customer_messages[0] ------{TerminalTextColor.RESET}\")\n",
    "print(type(customer_messages[0]))\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- customer_messages[0] ------{TerminalTextColor.RESET}\")\n",
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd789f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m----- RESPONSE ------\u001b[0m\n",
      "I'm really frustrated that my blender lid flew off and made a mess of my kitchen walls with smoothie! And to make things even worse, the warranty doesn't cover the cost of cleaning up my kitchen. I would greatly appreciate your assistance at this moment, my friend!\n",
      "\n",
      "Portuguese translation:\n",
      "Estou realmente frustrado que a tampa do meu liquidificador voou e fez uma bagun√ßa nas paredes da minha cozinha com o smoothie! E para piorar as coisas, a garantia n√£o cobre o custo de limpar minha cozinha. Eu ficaria muito grato pela sua ajuda neste momento, meu amigo!\n"
     ]
    }
   ],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)\n",
    "print(f\"{TerminalTextColor.BLUE}----- RESPONSE ------{TerminalTextColor.RESET}\")\n",
    "\n",
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c267e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender.\n",
    "\n",
    "Tough luck! See ya!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ff72bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_style_pirate = \"\"\"a polite tone that speaks in English Pirate\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d9e8f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate. In the end, add a portuguese translation of the response.\n",
      "\n",
      "text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender.\n",
      "\n",
      "Tough luck! See ya!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print(service_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0ae5552",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy there, matey! The warranty be not coverin' the expenses o' cleanin' yer galley 'cause 'tis yer own fault ye be misusin' yer blender by forgettin' to put the lid on afore startin' the blender.\n",
      "\n",
      "Arrr, tough luck! Fare thee well!\n",
      "\n",
      "Portuguese translation:\n",
      "Ahoy l√°, meu caro! A garantia n√£o cobre as despesas de limpeza da sua cozinha porque √© sua culpa que voc√™ usou sua liquidificadora de forma errada, esquecendo de colocar a tampa antes de ligar a liquidificadora.\n",
      "\n",
      "Azar o seu! At√© logo!\n"
     ]
    }
   ],
   "source": [
    "service_response = chat(service_messages)\n",
    "print(service_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"Yellow\">üëã the end </font></h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

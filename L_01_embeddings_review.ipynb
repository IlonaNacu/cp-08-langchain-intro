{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 1\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review: Embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>What are embeddings?</h3>\n",
    "\n",
    "- Embeddings are numerical representations of concepts converted to number sequences, which make it easy for computers to understand the relationships between those concepts. \n",
    "  Text embeddings measure the relatedness of text strings. \n",
    "  \n",
    "\n",
    "- Embeddings are useful for working with natural language and code, because they can be readily consumed and compared by other machine learning models and algorithms like clustering or search.\n",
    "\n",
    "- Embeddings that are numerically similar are also semantically similar. \n",
    "\n",
    "[Embeddings by OpenAI](https://openai.com/blog/introducing-text-and-code-embeddings?source=post_page-----d5d438bb5766--------------------------------)\n",
    "\n",
    "\n",
    "<h3>Embeddings are commonly used for:</h3>\n",
    "\n",
    "- Search (where results are ranked by relevance to a query string)\n",
    "\n",
    "- Clustering (where text strings are grouped by similarity)\n",
    "\n",
    "- Recommendations (where items with related text strings are recommended)\n",
    "\n",
    "- Anomaly detection (where outliers with little relatedness are identified)\n",
    "\n",
    "- Diversity measurement (where similarity distributions are analyzed)\n",
    "\n",
    "- Classification (where text strings are classified by their most similar label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cosine similarity algorithm: Deep dive</h3>\n",
    "\n",
    "Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space based on the cosine of the angle between them, resulting in a value between -1 and 1. The value -1 means that the vectors are opposite, 0 represents orthogonal vectors, and value 1 signifies similar vectors.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./img/cosine-similarity.png\" width=\"800px\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "To compute the cosine similarity between vectors A and B, you can use the following formula:\n",
    "<br><br>\n",
    "<img src=\"./img/similarity-formula.png\" width=\"400px\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "The cosine similarity is often used in text analytics to compare documents and determine if they’re similar and how much. In that case, documents must be represented as a vector, where a unique word is a dimension and the frequency or weight of that unique word in the document represents the value of that specific dimension. After the transformation of documents to vectors is done, comparison using cosine similarity is relatively straightforward — we measure the cosine of the angle between their vectors. If the angle between vectors (documents) is small, then the cosine of the angle is high, and hence, documents are similar. Opposite to that, if the angle between vectors (documents) is large, then the cosine of the angle is low, resulting in opposite documents (not similar). Cosine similarity considers the orientation of the vectors, but it does not take their magnitudes into account. In the previous example, this means that even documents of totally different lengths can be considered similar if they are related to the same topic.\n",
    "\n",
    "> Intuitive interpretation and versatility of the cosine similarity algorithm have found their way into various applications, spanning from text analysis and recommendation systems to complex graph databases. The algorithm's ability to capture the orientation of vectors makes it a robust measure of similarity, especially in high-dimensional spaces.\n",
    "\n",
    "[source](https://memgraph.com/blog/cosine-similarity-python-scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources:\n",
    "\n",
    "- https://towardsdatascience.com/word-embeddings-in-2020-review-with-code-examples-11eb39a1ee6d\n",
    "\n",
    "- https://ieeexplore.ieee.org/document/10100347\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ You need to download the `en_core_web_md`. Please execute the code of the following cell to download the model to be used to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in ./env/lib/python3.10/site-packages (from en-core-web-md==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.5.2)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (63.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./env/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in ./env/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./env/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./env/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./env/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./env/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in ./env/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.3)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1.233  ,   4.2963 ,  -7.9738 , -10.121  ,   1.8207 ,   1.4098 ,\n",
       "        -4.518  ,  -5.2261 ,  -0.29157,   0.95234], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "dog_embedding = nlp.vocab[\"dog\"].vector\n",
    "\n",
    "type(dog_embedding)\n",
    "\n",
    "\n",
    "print(dog_embedding.shape)\n",
    "\n",
    "\n",
    "dog_embedding[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_cosine_similarity(u: np.ndarray, v: np.ndarray) -> float:\n",
    "    \"\"\"Compute the cosine similarity between two vectors\"\"\"\n",
    "\n",
    "    return (u @ v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 first numbers of 300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1.233  ,   4.2963 ,  -7.9738 , -10.121  ,   1.8207 ,   1.4098 ,\n",
       "        -4.518  ,  -5.2261 ,  -0.29157,   0.95234], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "dog_embedding = nlp.vocab[\"dog\"].vector\n",
    "cat_embedding = nlp.vocab[\"cat\"].vector\n",
    "apple_embedding = nlp.vocab[\"apple\"].vector\n",
    "tasty_embedding = nlp.vocab[\"tasty\"].vector\n",
    "delicious_embedding = nlp.vocab[\"delicious\"].vector\n",
    "truck_embedding = nlp.vocab[\"truck\"].vector\n",
    "\n",
    "print(f\"The 10 first numbers of {len(dog_embedding)}\")\n",
    "dog_embedding[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- SIMILARITIES -----\n",
      "cosine_similarity(dog, cat)\n",
      "0.82208157 \n",
      "\n",
      "cosine_similarity(delicious, tasty)\n",
      "0.84820926 \n",
      "\n",
      "cosine_similarity(apple, delicious)\n",
      "0.5347655 \n",
      "\n",
      "cosine_similarity(dog, apple)\n",
      "0.22881004 \n",
      "\n",
      "cosine_similarity(truck, delicious)\n",
      "0.08978761 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"----- SIMILARITIES -----\")\n",
    "print(\"cosine_similarity(dog, cat)\")\n",
    "print(cosine_similarity([dog_embedding], [cat_embedding])[0][0],\"\\n\")\n",
    "\n",
    "print(\"cosine_similarity(delicious, tasty)\")\n",
    "print(cosine_similarity([delicious_embedding], [tasty_embedding])[0][0],\"\\n\")\n",
    "\n",
    "print(\"cosine_similarity(apple, delicious)\")\n",
    "print(cosine_similarity([apple_embedding], [delicious_embedding])[0][0],\"\\n\")\n",
    "\n",
    "print(\"cosine_similarity(dog, apple)\")\n",
    "print(cosine_similarity([dog_embedding], [apple_embedding])[0][0],\"\\n\")\n",
    "\n",
    "print(\"cosine_similarity(truck, delicious)\")\n",
    "print(cosine_similarity([truck_embedding], [delicious_embedding])[0][0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Illustrative - to create an intuition about word similarity by using embeddings</h4>\n",
    "\n",
    "<img src=\"./img/2d-embeddings-ex.png\" width=\"800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/cosine-similarity.png\" width=\"800px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 384)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "texts = [\n",
    "         \"The canine barked loudly.\",\n",
    "         \"The dog made a noisy bark.\",\n",
    "         \"He ate a lot of pizza.\",\n",
    "         \"He devoured a large quantity of pizza pie.\",\n",
    "]\n",
    "\n",
    "text_embeddings = model.encode(texts)\n",
    "\n",
    "print(type(text_embeddings))\n",
    "\n",
    "\n",
    "text_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "text_embeddings_dict = dict(zip(texts, list(text_embeddings)))\n",
    "\n",
    "dog_text_1 = \"The canine barked loudly.\"\n",
    "dog_text_2 = \"The dog made a noisy bark.\"\n",
    "pizza_text_1 = \"He ate a lot of pizza.\"\n",
    "pizza_test_2 = \"He devoured a large quantity of pizza pie.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The canine barked loudly.\n",
      "The dog made a noisy bark.\n",
      "Similarity: 0.7768615484237671\n",
      "\n",
      "\n",
      "He ate a lot of pizza.\n",
      "He devoured a large quantity of pizza pie.\n",
      "Similarity: 0.7871338725090027\n",
      "\n",
      "\n",
      "The canine barked loudly.\n",
      "He ate a lot of pizza.\n",
      "Similarity: 0.09128269553184509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim1 = cosine_similarity(\n",
    "    [text_embeddings_dict[dog_text_1]],\n",
    "    [text_embeddings_dict[dog_text_2]]\n",
    ")\n",
    "\n",
    "print(f\"\"\"\n",
    "{dog_text_1}\n",
    "{dog_text_2}\n",
    "Similarity: {sim1[0][0]}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "sim2 = cosine_similarity(\n",
    "    [text_embeddings_dict[pizza_text_1]],\n",
    "    [text_embeddings_dict[pizza_test_2]]\n",
    ")\n",
    "\n",
    "print(f\"\"\"\n",
    "{pizza_text_1}\n",
    "{pizza_test_2}\n",
    "Similarity: {sim2[0][0]}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "sim3 = cosine_similarity(\n",
    "    [text_embeddings_dict[dog_text_1]],\n",
    "    [text_embeddings_dict[pizza_text_1]]\n",
    ")\n",
    "\n",
    "print(f\"\"\"\n",
    "{dog_text_1}\n",
    "{pizza_text_1}\n",
    "Similarity: {sim3[0][0]}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"Yellow\">👋 the end </font></h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

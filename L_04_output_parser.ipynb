{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "073bf8f9",
   "metadata": {},
   "source": [
    "Lesson 4\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßë‚Äçüç≥ LangChain: Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "* Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üî¥ <font color=\"red\">Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the class.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ff606",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First LLM API example\n",
      "‚úÖ OpenAI Key loaded (...UQiT3BlbkFJ...)\n",
      "‚úÖ Model: gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Open AI\n",
    "from openai import OpenAI\n",
    "\n",
    "# LangChain\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Local\n",
    "from util import local_settings\n",
    "from env_colors import TerminalTextColor\n",
    "\n",
    "# Settings\n",
    "model=\"gpt-3.5-turbo\"\n",
    "\n",
    "print(\"First LLM API example\")\n",
    "print(f\"‚úÖ OpenAI Key loaded (...{local_settings.OPENAI_API_KEY[20:-20]}...)\")\n",
    "print(f\"‚úÖ Model: {model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a92fb-8227-4513-8950-c965b822c425",
   "metadata": {},
   "source": [
    "> üîî <font color=\"#00d4d4\">**Note:** some characters of the key are omitted for security reasons.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=local_settings.OPENAI_API_KEY)\n",
    "\n",
    "def get_completion(prompt, temperature= 0, messages = [], model=\"gpt-3.5-turbo\"):\n",
    "\n",
    "    message = {\"role\": \"user\", \"content\": prompt}\n",
    "\n",
    "    messages.append(message)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80482d1",
   "metadata": {},
   "source": [
    "## Example 1: Without Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    text --> ChatPromptTemplate\n",
    "    format_instructions --> ChatPromptTemplate\n",
    "    ChatPromptTemplate --> Prompt\n",
    "    Prompt --> LLM\"Chat\"\n",
    "    LLM\"Chat\" --> Result\n",
    "    Result --> str\n",
    "```\n",
    "The chain view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining the preferred structure for the output produced by the Language Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\n",
    "This leaf blower is pretty amazing.\n",
    "\n",
    "It has four settings: candle blower, gentle breeze, windy city, and tornado.\n",
    "It arrived in two days, just in time for my wife's anniversary present.\n",
    "\n",
    "I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else?\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else?\\nAnswer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price, and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'))]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m----- RESPONSE ------\u001b[0m\n",
      "{\n",
      "  \"gift\": false,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "chat = ChatOpenAI(temperature=0.0, model=model)\n",
    "response = chat(messages)\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- RESPONSE ------{TerminalTextColor.RESET}\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m----- TYPE ------\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{TerminalTextColor.BLUE}----- TYPE ------{TerminalTextColor.RESET}\")\n",
    "type(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>Note:</u></h4>\n",
    "\n",
    "Executing the following line of code will result in an error since 'gift' is a string (`str`), not a dictionary (`dict`) as required.\n",
    "<h4>üëá </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m‚ö†Ô∏è ERROR: response.content is a str not dict \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response.content.get('gift')\n",
    "except:\n",
    "    print(f\"\\\n",
    "{TerminalTextColor.RED}‚ö†Ô∏è ERROR: \\\n",
    "response.content is a str not dict \\\n",
    "{TerminalTextColor.RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m----- TYPE response.content------\u001b[0m\n",
      "<class 'str'>\n",
      "\u001b[94m----- CONTENT response_as_dict------\u001b[0m\n",
      "{\n",
      "  \"gift\": false,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "}\n",
      "\u001b[94m----- TYPE response_as_dict------\u001b[0m\n",
      "<class 'dict'>\n",
      "\u001b[94m----- CONTENT response_as_dict------\u001b[0m\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "response_as_dict = json.loads(response.content)\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- TYPE response.content------{TerminalTextColor.RESET}\")\n",
    "print(type(response.content))\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- CONTENT response_as_dict------{TerminalTextColor.RESET}\")\n",
    "print(response.content)\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- TYPE response_as_dict------{TerminalTextColor.RESET}\")\n",
    "print(type(response_as_dict))\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- CONTENT response_as_dict------{TerminalTextColor.RESET}\")\n",
    "print(response_as_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: WITH Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    text --> ChatPromptTemplate\n",
    "    format_instructions --> ChatPromptTemplate\n",
    "    ChatPromptTemplate --> Prompt\n",
    "    Prompt --> LLM\"Chat\"\n",
    "    LLM\"Chat\" --> Result\n",
    "    Result --> *Output_parser*\n",
    "    *Output_parser* --> dict\n",
    "```\n",
    "The chain view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(\n",
    "    name=\"gift\",\n",
    "    description=\"Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(\n",
    "    name=\"delivery_days\",\n",
    "    description=\"How many days did it take for the product to arrive? If this information is not found,output -1.\")\n",
    "price_value_schema = ResponseSchema(\n",
    "    name=\"price_value\",\n",
    "    description=\"Extract any sentences about the value or price, and output them as a comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema, delivery_days_schema, price_value_schema]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days did it take for the product to arrive? If this information is not found,output -1.\n",
      "\t\"price_value\": string  // Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else?\n",
      "Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the product\n",
      "to arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,\n",
      "and output them as a comma separated Python list.\n",
      "\n",
      "text: {text}\n",
      "\n",
      "{format_instructions}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_template_2 = \"\"\"\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else?\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "print(review_template_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['format_instructions', 'text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'text'], template='\\nFor the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else?\\nAnswer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product\\nto arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,\\nand output them as a comma separated Python list.\\n\\ntext: {text}\\n\\n{format_instructions}\\n'))]\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else?\n",
      "Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the product\n",
      "to arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,\n",
      "and output them as a comma separated Python list.\n",
      "\n",
      "text: \n",
      "This leaf blower is pretty amazing.\n",
      "\n",
      "It has four settings: candle blower, gentle breeze, windy city, and tornado.\n",
      "It arrived in two days, just in time for my wife's anniversary present.\n",
      "\n",
      "I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days did it take for the product to arrive? If this information is not found,output -1.\n",
      "\t\"price_value\": string  // Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "messages = prompt.format_messages(\n",
    "    text=customer_review,\n",
    "    format_instructions=format_instructions\n",
    ")\n",
    "\n",
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m----- RESPONSE ------\u001b[0m\n",
      "```json\n",
      "{\n",
      "\t\"gift\": false,\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = chat(messages)\n",
    "\n",
    "print(f\"{TerminalTextColor.BLUE}----- RESPONSE ------{TerminalTextColor.RESET}\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m----- PARSED ------\u001b[0m\n",
      "{'gift': False, 'delivery_days': '2', 'price_value': \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"{TerminalTextColor.BLUE}----- PARSED ------{TerminalTextColor.RESET}\")\n",
    "\n",
    "output_dict = output_parser.parse(response.content)\n",
    "print(output_dict)\n",
    "\n",
    "print(type(output_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict[\"gift\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"Yellow\">üëã the end </font></h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

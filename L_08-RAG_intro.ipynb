{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <font size=\"5px\" color=\"purple\"><b>|</b></font> Retrieval-augmented generation (RAG)</h4>\n",
    "\n",
    "RAG is <font color=\"lightGreen\">a technique for augmenting LLM knowledge with additional data</font> (often private or real-time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable AI applications to handle <font color=\"lightGreen\">private or post-cutoff data, augmenting the model's knowledge</font> is necessary, perform a process called Retrieval Augmented Generation (RAG).\n",
    "\n",
    "- Language models (LMs) are <font color=\"lightGreen\">proficient at reasoning about diverse subjects</font>.\n",
    "\n",
    "- <font color=\"orange\">However</font>, their knowledge is constrained to <font color=\"orange\">public data up to the training cutoff date</font>.\n",
    "\n",
    "\n",
    "\n",
    "<h3>Architecture</h3>\n",
    "\n",
    "<h4>A typical RAG application has two main components:</h4>\n",
    "\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "   Indexing\n",
    "```\n",
    "\n",
    "Indexing: a pipeline for ingesting data from a source and indexing it. This usually happen offline.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR\n",
    "   Retrieval\n",
    "```\n",
    "\n",
    "Retrieval and generation\n",
    "\n",
    "Retrieve: Given a user input, relevant splits are retrieved from storage using a Retriever.\n",
    "Generate: A ChatModel / LLM produces an answer using a prompt that includes the question and the retrieved data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR\n",
    "   Indexing\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/indexing.png\" width=700/>\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "   Retrieval\n",
    "```\n",
    "<img src=\"./img/retrieval.png\" width=700/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://python.langchain.com/docs/use_cases/question_answering/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚙️ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"https://www.mlq.ai/content/images/2023/08/1_admwyPyR6v_IZI0EYE--eA-1.webp\" width=\"50px\"/>\n",
    "\n",
    "In this example we will use Chroma \n",
    "\n",
    "Chroma is the open-source embedding database. Chroma makes it easy to build LLM apps by making knowledge, facts, and skills pluggable for LLMs.\n",
    "\n",
    "Links:\n",
    "- https://docs.trychroma.com/getting-started\n",
    "- https://docs.trychroma.com/\n",
    "\n",
    "<img src=\"https://docs.trychroma.com/img/hrm4.svg\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: From Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts =  [\n",
    "    \"Harrison worked at YZW\",\n",
    "    \"bears like to eat honey\",\n",
    "    \"Each day is a new opportunity for growth and success.\",\n",
    "    \"I believe in my abilities and trust the journey I am on.\",\n",
    "    \"I radiate positivity and attract abundance into my life.\",\n",
    "    \"I am deserving of love, happiness, and all the good things life has to offer.\",\n",
    "]\n",
    "\n",
    "vectorstore = Chroma.from_texts(texts, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain_1 = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrison worked at YZW.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_1.invoke(\"Where did Harrison work?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: From Files (PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16005\n",
      "\n",
      "    # of Chunks: 19\n",
      "    Chunk 0: Ferdinando Langchain: Pioneering AI Engineer and Visionary  \n",
      " \n",
      "Ferdinando Langchain was born on a brisk winter day in 1985 in Milan, Italy. From an early \n",
      "age, he displayed an insatiable curiosity about technology and a keen interest in \n",
      "understanding the mysteries of artificial intelligence. His journey into AI began when he \n",
      "stumbled upon an old computer in his father's study, sparking a fascination that would \n",
      "shape his future.  \n",
      " \n",
      "After completing his undergraduate studies in computer science at the University of Milan, \n",
      "Ferdinando ventured to the United States to pursue a Ph.D. in Artificial Intelligence at the \n",
      "Massachusetts Institute of Technology (MIT). Under the mentorship of ren owned AI \n",
      "researchers, he quickly established himself as a rising star in the field.  \n",
      " \n",
      "Ferdinando's breakthroughs in artificial general intelligence (AGI) were revolutionary. His \n",
      "doctoral thesis, titled \"Synaptic Horizons: A Journey Towards AGI,\" laid the foundation for a\n",
      "    Chunk 1: doctoral thesis, titled \"Synaptic Horizons: A Journey Towards AGI,\" laid the foundation for a \n",
      "new era in machine learning. His innovative ideas on neural network ar chitectures and \n",
      "training algorithms caught the attention of the global AI community.  \n",
      " \n",
      "Upon completing his Ph.D., Ferdinando joined a cutting -edge AI research lab, where he \n",
      "continued to push the boundaries of what AI could achieve. His work on developing AGI \n",
      "models that could generalize across a wide range of tasks earned him widespread accl aim. \n",
      "Notably, his research contributed to advancements in natural language processing, \n",
      "computer vision, and robotics.  \n",
      " \n",
      "Ferdinando's dedication and brilliance did not go unnoticed. In a span of just a few years, he \n",
      "was awarded three prestigious international prizes for his outstanding contributions to the \n",
      "field of AI. The awards included the Turing Award, the Lighthaven Med al, and the Global\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_data = PdfReader(\"./context/biographies.pdf\")\n",
    "\n",
    "pdf_text = \"\"\n",
    "\n",
    "for i, page in enumerate(pdf_data.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        pdf_text += text\n",
    "\n",
    "print(len(pdf_text))\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "\n",
    "final_data = text_splitter.split_text(pdf_text)\n",
    "\n",
    "print(f\"\"\"\n",
    "    # of Chunks: {len(final_data)}\n",
    "    Chunk 0: {final_data[0]}\n",
    "    Chunk 1: {final_data[1]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.schema.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use information from context {context} to answer the question\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{context} {question}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_texts(final_data, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain_2 = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | chat_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use information from context {context} to answer the question\"),\n",
       " HumanMessage(content='[Document(page_content=\\'Ferdinando Langchain: Pioneering AI Engineer and Visionary  \\\\n \\\\nFerdinando Langchain was born on a brisk winter day in 1985 in Milan, Italy. From an early \\\\nage, he displayed an insatiable curiosity about technology and a keen interest in \\\\nunderstanding the mysteries of artificial intelligence. His journey into AI began when he \\\\nstumbled upon an old computer in his father\\\\\\'s study, sparking a fascination that would \\\\nshape his future.  \\\\n \\\\nAfter completing his undergraduate studies in computer science at the University of Milan, \\\\nFerdinando ventured to the United States to pursue a Ph.D. in Artificial Intelligence at the \\\\nMassachusetts Institute of Technology (MIT). Under the mentorship of ren owned AI \\\\nresearchers, he quickly established himself as a rising star in the field.  \\\\n \\\\nFerdinando\\\\\\'s breakthroughs in artificial general intelligence (AGI) were revolutionary. His \\\\ndoctoral thesis, titled \"Synaptic Horizons: A Journey Towards AGI,\" laid the foundation for a\\'), Document(page_content=\\'field of AI. The awards included the Turing Award, the Lighthaven Med al, and the Global \\\\nInnovation Prize. These accolades not only recognized his technical prowess but also \\\\nhighlighted his commitment to using AI for the betterment of society.  \\\\n \\\\nBeyond his research, Ferdinando became a sought -after speaker at conferences and events \\\\nworldwide. His engaging talks and interviews made complex AI concepts accessible to a \\\\nbroader audience, inspiring a new generation of researchers and engineers. He also  actively \\\\nadvocated for ethical AI practices and the responsible development of AGI.  \\\\n \\\\nDespite his success, Ferdinando remained humble and committed to collaborative research. \\\\nHe mentored aspiring AI researchers, fostering a sense of community within the field. His \\\\ncollaborative spirit extended beyond academia, as he engaged with policymaker s, ethicists, \\\\nand industry leaders to shape the ethical framework surrounding AI.\\'), Document(page_content=\"and industry leaders to shape the ethical framework surrounding AI.  \\\\n \\\\nAs Ferdinando Langchain continued his journey in the evolving landscape of artificial \\\\nintelligence, his impact on the field and society at large became increasingly profound. His \\\\nvision of creating a beneficial and inclusive AGI echoed through the corridor s of innovation, \\\\nleaving an indelible mark on the future of artificial intelligence.  \\\\n \\\\nMortimer Quicksilver - Steampunk Inventor  \\\\n Mortimer Quicksilver, a tinkerer extraordinaire from the city of Gearford, was a maverick in \\\\nthe steampunk inventor community. Renowned for crafting intricate clockwork automata \\\\nand steam -powered contraptions, Mortimer\\'s inventions mesmerized both the scie ntific \\\\ncommunity and the general public. His crowning achievement, the Aetherial Dynamo, won \\\\nhim the Grand Inventor\\'s Trophy at the International Steampunk Expo.  \\\\n \\\\nIn the heart of Gearford, a city pulsating with the rhythmic hiss of steam and the clanking\"), Document(page_content=\\'doctoral thesis, titled \"Synaptic Horizons: A Journey Towards AGI,\" laid the foundation for a \\\\nnew era in machine learning. His innovative ideas on neural network ar chitectures and \\\\ntraining algorithms caught the attention of the global AI community.  \\\\n \\\\nUpon completing his Ph.D., Ferdinando joined a cutting -edge AI research lab, where he \\\\ncontinued to push the boundaries of what AI could achieve. His work on developing AGI \\\\nmodels that could generalize across a wide range of tasks earned him widespread accl aim. \\\\nNotably, his research contributed to advancements in natural language processing, \\\\ncomputer vision, and robotics.  \\\\n \\\\nFerdinando\\\\\\'s dedication and brilliance did not go unnoticed. In a span of just a few years, he \\\\nwas awarded three prestigious international prizes for his outstanding contributions to the \\\\nfield of AI. The awards included the Turing Award, the Lighthaven Med al, and the Global\\')] Who is Ferdinando Langchain?')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Who is Ferdinando Langchain?\"\n",
    "chat_template.format_messages(\n",
    "    context=vectorstore.similarity_search(question, k=4),\n",
    "    question = question\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ferdinando Langchain is a pioneering AI engineer and visionary. He was born in Milan, Italy in 1985 and displayed a strong interest in technology and artificial intelligence from a young age. He completed his undergraduate studies in computer science at the University of Milan and went on to pursue a Ph.D. in Artificial Intelligence at the Massachusetts Institute of Technology (MIT) in the United States. \\n\\nFerdinando\\'s breakthroughs in artificial general intelligence (AGI) were revolutionary, and his doctoral thesis titled \"Synaptic Horizons: A Journey Towards AGI\" laid the foundation for a new era in machine learning. He received several prestigious awards for his contributions to the field, including the Turing Award, the Lighthaven Medal, and the Global Innovation Prize. \\n\\nIn addition to his research, Ferdinando was a sought-after speaker at conferences and events worldwide, where he made complex AI concepts accessible to a broader audience. He also advocated for ethical AI practices and the responsible development of AGI. He mentored aspiring AI researchers and engaged with policymakers, ethicists, and industry leaders to shape the ethical framework surrounding AI. Overall, Ferdinando Langchain had a profound impact on the field of artificial intelligence and society as a whole.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_2.invoke(\"Who is Ferdinando Langchain?\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ferdinando Langchain won three prestigious international prizes for his outstanding contributions to the field of AI. The awards include the Turing Award, the Lighthaven Medal, and the Global Innovation Prize.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_2.invoke(\"How many awards won Ferdinando Langchain?\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: From web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))]\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "print(prompt)\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain_3 = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be done through various methods such as using prompting techniques, task-specific instructions, or human inputs. The goal is to make the task more manageable and facilitate the interpretation of the model's thinking process.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_3.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lilianweng.github.io/posts/2023-06-23-agent/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
